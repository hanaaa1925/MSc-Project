{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "current-wrestling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba851580600b45b2ab5cadc00be4cf35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 23:05:19 INFO: Downloading default packages for language: en (English)...\n",
      "2021-11-16 23:05:21 INFO: File exists: /Users/yhl125/stanza_resources/en/default.zip.\n",
      "2021-11-16 23:05:25 INFO: Finished downloading models and saved to /Users/yhl125/stanza_resources.\n",
      "2021-11-16 23:05:25 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-11-16 23:05:25 INFO: Use device: cpu\n",
      "2021-11-16 23:05:25 INFO: Loading: tokenize\n",
      "2021-11-16 23:05:25 INFO: Loading: ner\n",
      "2021-11-16 23:05:25 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# data preprocess tools\n",
    "from nltk import data\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "import stanza\n",
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "confused-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('./dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "pediatric-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].str.lower()\n",
    "data['content'] = data['content'].apply(lambda string: ' '.join([word for word in string.split(' ') if not word.rstrip(' ').startswith('@')]))\n",
    "data['content'] = data['content'].apply(lambda string: ' '.join([word for word in string.split(' ') if not word.rstrip(' ').startswith('#')]))\n",
    "data['content'] = data['content'].apply(lambda string: ' '.join([word for word in string.split(' ') if not word.rstrip(' ').startswith('http')]))\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('rt')\n",
    "\n",
    "def text_process(text):\n",
    "    tokenizer = RegexpTokenizer('[a-z0-9]+')\n",
    "    token = tokenizer.tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    token = [lemmatizer.lemmatize(w) for w in token if lemmatizer.lemmatize(w) not in stop_words]\n",
    "    return token\n",
    "\n",
    "data['content'] = data['content'].apply(text_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "purple-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['content']\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 71)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "non_sensitive_train = train[train['label'] == 0]\n",
    "sensitive_train = train[train['label'] == 1]\n",
    "\n",
    "# non_sensitive_train_part = non_sensitive_train['content'].sample(139, random_state=42)\n",
    "# sensitive_train_part = sensitive_train['content'].sample(139, random_state=42)\n",
    "\n",
    "non_sensitive_trainset = non_sensitive_train['content']\n",
    "sensitive_trainset = non_sensitive_train['content']\n",
    "\n",
    "vocablist = []\n",
    "\n",
    "for i in pd.concat([non_sensitive_trainset, sensitive_trainset]):\n",
    "    vocablist += i\n",
    "\n",
    "trainset_texts = [' '.join(content) for content in np.concatenate((non_sensitive_trainset.values, sensitive_trainset.values))]\n",
    "\n",
    "train_all_texts = [' '.join(content) for content in train['content']]\n",
    "\n",
    "test_all_texts = [' '. join(content) for content in test['content']]\n",
    "\n",
    "# trainset_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "large-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<129x2269 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1173 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "trainset_fit = cv.fit(trainset_texts)\n",
    "train_all_count = cv.transform(train_all_texts)\n",
    "test_all_count = cv.transform(test_all_texts)\n",
    "\n",
    "train_all_count\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "train_tfidf_matrix = tfidf.fit_transform(train_all_count)\n",
    "test_tfidf_matrix = tfidf.fit_transform(test_all_count)\n",
    "\n",
    "test_all_count\n",
    "# print(train_tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "handmade-dallas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:93.957%, precision:97.235%, recall:89.407%, dts1：93.96%\n",
      "accuracy:79.845%, precision:85.455%, recall:72.308%, dts2：79.84%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "model = MultinomialNB(alpha=1.1, fit_prior=True, class_prior=None).fit(train_tfidf_matrix, y_train)\n",
    "#model.score(test_tfidf_matrix, y_test)\n",
    "\n",
    "y_train_pdt = model.predict(train_tfidf_matrix)\n",
    "y_test_pdt = model.predict(test_tfidf_matrix)\n",
    "\n",
    "dts1 = len(np.where(y_train_pdt==y_train)[0])/len(y_train)\n",
    "dts2 = len(np.where(y_test_pdt==y_test)[0])/len(y_test)\n",
    "\n",
    "acc1 = accuracy_score(y_train_pdt, y_train)\n",
    "acc2 = accuracy_score(y_test_pdt, y_test)\n",
    "\n",
    "pre1 = precision_score(y_train_pdt, y_train)\n",
    "pre2 = precision_score(y_test_pdt, y_test)\n",
    "\n",
    "rec1 = recall_score(y_train_pdt, y_train)\n",
    "rec2 = recall_score(y_test_pdt, y_test)\n",
    "\n",
    "print(\"accuracy:{:.3f}%, precision:{:.3f}%, recall:{:.3f}%, dts1：{:.2f}%\".format(acc1*100, pre1*100, rec1*100, dts1*100))\n",
    "print(\"accuracy:{:.3f}%, precision:{:.3f}%, recall:{:.3f}%, dts2：{:.2f}%\".format(acc2*100, pre2*100, rec2*100, dts2*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "competent-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"@Alice My name is Bob, Today is my Birthday. My salary is $2000 per month, I work in Microsoft.My workmate is bad\"\n",
    "#text = \"Today is my Birthday.\"\n",
    "#text = \"My salary is $2000 per month\"\n",
    "#text = \"My boss Roan is a foolish man\"\n",
    "#text = \"I hope Alice get fired tommorrow\"\n",
    "#text = \"My workmate is nice\"\n",
    "#text = \"My workmate is bad\"\n",
    "#text = \"My workmate is shameless\"\n",
    "#text = \"My employee John is good\"\n",
    "#text = \"My employee John is good but mean\"\n",
    "#text = \"My employee John is stupid, but he pays me a lot\"\n",
    "\n",
    "df = pd.read_excel('./test.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "#df = pd.DataFrame({\"text\":text},index=[\"0\"])\n",
    "\n",
    "df['content'] = df['content'].str.lower()\n",
    "df['content'] = df['content'].apply(lambda string: ' '.join([word for word in string.split(' ') if not word.rstrip(' ').startswith('@')]))\n",
    "df['content'] = df['content'].apply(lambda string: ' '.join([word for word in string.split(' ') if not word.rstrip(' ').startswith('#')]))\n",
    "df['content'] = df['content'].apply(lambda string: ' '.join([word for word in string.split(' ') if not word.rstrip(' ').startswith('http')]))\n",
    "df['content'] = df['content'].apply(text_process)\n",
    "#print(df['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "aging-neutral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++\n",
      "[0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 1]\n",
      "0.6440677966101694\n"
     ]
    }
   ],
   "source": [
    "#print(df['content'])\n",
    "y_label = df['label']\n",
    "text_content = [' '.join(content) for content in df['content']]\n",
    "#print(text_content)\n",
    "#print('---')\n",
    "\n",
    "text_count = cv.transform(text_content)\n",
    "#print(text_count)\n",
    "print('+++')\n",
    "text_tfidf_matrix = tfidf.fit_transform(text_count)\n",
    "pre = model.predict(text_tfidf_matrix)\n",
    "print(pre)\n",
    "acc_test = accuracy_score(pre, y_label)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "worth-norway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'tpr')"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = model.predict_proba(test_tfidf_matrix)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "\n",
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.3f' % roc_auc)\n",
    "plt.title('roc = {:.4f}'.format(roc_auc))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-second",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "cv = CountVectorizer()\n",
    "trainset_fit = cv.fit(trainset_texts)\n",
    "train_all_count = cv.fit_transform(train_all_texts)\n",
    "test_all_count = cv.transform(test_all_texts)\n",
    "\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "train_tfidf_matrix = sel.fit_transform(train_all_count)\n",
    "test_tfidf_matrix = sel.fit_transform(test_all_count)\n",
    "\n",
    "#test_sel\n",
    "#\n",
    "#tfidf = TfidfTransformer()\n",
    "#train_tfidf_matrix = tfidf.fit_transform(train_sel)\n",
    "#test_tfidf_matrix = tfidf.fit_transform(test_sel)\n",
    "\n",
    "test_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "surprising-preference",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PCA does not support sparse input. See TruncatedSVD for a possible alternative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-764-42cbde0f2cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnewData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_all_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnewData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \"\"\"\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# This is more informative than the generic one raised by check_array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             raise TypeError('PCA does not support sparse input. See '\n\u001b[0m\u001b[1;32m    395\u001b[0m                             'TruncatedSVD for a possible alternative.')\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: PCA does not support sparse input. See TruncatedSVD for a possible alternative."
     ]
    }
   ],
   "source": [
    "#\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "newData = pca.fit_transform(train_all_count)\n",
    "print (newData)\n",
    "\n",
    "pre = clf.predict(X)\n",
    "Y = [1,1,0,0,1,0,0,1,1,0]\n",
    "import matplotlib.pyplot as plt\n",
    "L1 = [n[0] for n in newData]\n",
    "L2 = [n[1] for n in newData]\n",
    "plt.scatter(L1,L2,c=pre,s=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "appointed-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 词袋\n",
    "from gensim import models\n",
    "from gensim import corpora\n",
    "\n",
    "train_word_list = []\n",
    "for corpu in train_all_texts:\n",
    "    seg_list = [i for i in corpu] \n",
    "    word_list.append(seg_list)\n",
    "\n",
    "#print(word_list)\n",
    "\n",
    "test_word_list = []\n",
    "for corpu in test_all_texts:\n",
    "    seg_list = [i for i in corpu] \n",
    "    test_word_list.append(seg_list)\n",
    "\n",
    "    \n",
    "train_dictionary = corpora.Dictionary(train_word_list)\n",
    "test_dictionary = corpora.Dictionary(test_word_list)\n",
    "\n",
    "#print(dictionary.token2id)\n",
    "trainset = [dictionary.doc2bow(word) for word in train_word_list]\n",
    "testset = [dictionary.doc2bow(word) for word in test_word_list]\n",
    "\n",
    "train_tfidf = models.TfidfModel(trainset)\n",
    "test_tfidf = models.TfidfModel(testset)\n",
    "\n",
    "train_tfidf_vec = []\n",
    "for i in trainset:\n",
    "    string_tfidf = train_tfidf[i]\n",
    "    train_tfidf_vec.append(string_tfidf)\n",
    "print(train_tfidf_vec)\n",
    "\n",
    "\n",
    "test_tfidf_vec = []\n",
    "for i in testset:\n",
    "    string_tfidf = test_tfidf[i]\n",
    "    test_tfidf_vec.append(string_tfidf)\n",
    "#print(test_tfidf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-minister",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
